{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "\n",
    "def test_load_dfs(df_1,df_2):\n",
    "    template_1 = joblib.load('tests/loans_template.pkl').dtypes\n",
    "    template_3 = joblib.load('tests/recharges_template.pkl').dtypes\n",
    "    assert (df_1.dtypes == template_1).all()\n",
    "    assert (df_2.dtypes == template_3).all()\n",
    "\n",
    "    return df_1,df_2\n",
    "\n",
    "\n",
    "def load_dfs(paths=[\n",
    "    'Brazil_DS_loans_2019-11-10_2019-12-05.csv',\n",
    "    'Brazil_DS_prev_loans.csv',\n",
    "    'Brazil_DS_recharges_2019-08-10_2019-12-05.csv']):\n",
    "    \n",
    "    loans_actual = pd.read_csv(paths[0],date_parser=lambda x: pd.to_datetime(x, format='%Y-%m-%d'),parse_dates=['created_at','paid_at'])\n",
    "    loans_prev = pd.read_csv(paths[1],date_parser=lambda x: pd.to_datetime(x, format='%Y-%m-%d'),parse_dates=['created_at','paid_at'])\n",
    "    loans = pd.concat([loans_actual,loans_prev],ignore_index=True)\n",
    "    recharges = pd.read_csv(paths[2],date_parser=lambda x: pd.to_datetime(x, format='%Y-%m-%d'),parse_dates=['recharge_timestamp'])\n",
    "    #return  test_load_dfs(loans, recharges)\n",
    "    return  loans, recharges\n",
    "\n",
    "\n",
    "loans, recharges = load_dfs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Falta fazer\n",
    "\n",
    "* Otimização dos parametros com k-fold\n",
    "* Criar os cenários para escolher qual melhor modelo\n",
    "* Criar os mocks de teste do feature eng\n",
    "* Relátorio final\n",
    "* Se der tempo fazer um CLI básico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É interessante observar que os emprestimos não pagos não varia muito da mediana populacional, 5, entretanto utilizar essa informação pode gerar bias no modelo preditivo.\n",
    "\n",
    "\n",
    "LEMBRETES:\n",
    "    Criar intervalos de loans permitidos para cada usuário\n",
    "    Fazes dois mocks para as funções de feature eng\n",
    "\n",
    "Notas:\n",
    "    Distribuição acumulado inad. \n",
    "        target_sum\n",
    "        0    7044\n",
    "        1    2463\n",
    "        2       5\n",
    "        4       1\n",
    "\n",
    "#t_loans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print('General Loans stats \\n',t_loans['amount'].describe(),'\\n',f\"Median : {t_loans['amount'].median()}\")\n",
    "#print('Paid stats \\n',t_loans.query('target == 0').groupby('uuid').sum('amount').sort_values('amount',ascending=False)['amount'].describe())\n",
    "#print('Not Paid stats \\n',t_loans.query('target == 1').groupby('uuid').sum('amount').sort_values('amount',ascending=False)['amount'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2019-12-04 23:54:57.280521')"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loans['created_at'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['uuid', 'loan_id', 'amount', 'created_at', 'paid_at',\n",
       "       'paid_days_interval', 'target'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loans.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2019-12-04 23:54:57.280521')"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loans['created_at'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last_date 2019-12-04 00:00:00\n",
      "limit_date 2019-12-04 23:54:57.280521\n",
      "train_loans:  (18336, 5)\n",
      "test_loans:  (625, 5)\n",
      "train_X:  (238, 5)\n",
      "train_y:  (238,)\n",
      "Confusion Matrix: \n",
      " [[0 0]\n",
      " [8 8]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      0.50      0.67        16\n",
      "\n",
      "    accuracy                           0.50        16\n",
      "   macro avg       0.50      0.25      0.33        16\n",
      "weighted avg       1.00      0.50      0.67        16\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/enniobastos/miniconda3/envs/juvo_test_pycaret/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import List\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class FeatureEngineering:\n",
    "    train_loans: pd.DataFrame\n",
    "    test_loans: pd.DataFrame\n",
    "    train_recharges: pd.DataFrame\n",
    "    days_to_default:int = 60\n",
    "    \n",
    "\n",
    "    def __post_init__(self):\n",
    "\n",
    "        self.train_loans = self.__feature_eng_loans(self.train_loans.copy())\n",
    "        self.test_loans = self.__feature_eng_loans(self.test_loans.copy())\n",
    "        self.train_recharges = self.__feature_eng_recharges(self.train_recharges.copy())\n",
    "        \n",
    "\n",
    "    def __feature_eng_loans(self,df_l: pd.DataFrame) -> pd.DataFrame:\n",
    "            '''\n",
    "            Feature engineering for loans dataframe using historical data\n",
    "            already_default: 0 if not defaulted, 1 if defaulted\n",
    "            sum_amoun: sum amount of all previous loans paid\n",
    "            count_loans: number of previous loans paid\n",
    "\n",
    "            :param df_l: loans dataframe\n",
    "            :return: feature engineered loans dataframe\n",
    "            '''\n",
    "            #calc days interval between dates\n",
    "            df_l['paid_days_interval'] = (df_l['paid_at'] - df_l['created_at'])\n",
    "            df_l['target'] = df_l['paid_days_interval'].apply(lambda x: 1 if x.days > self.days_to_default else 0)\n",
    "\n",
    "            already_default = df_l.groupby('uuid').sum()['target'].apply(lambda x: 1 if x > 0 else 0)\n",
    "            sum_amount = df_l.query('target == 0').groupby('uuid').sum()['amount']\n",
    "            count_loans = df_l.query('target == 0').groupby('uuid').count()['amount']\n",
    "\n",
    "            out_df = pd.DataFrame(df_l.groupby('uuid').count().index)\n",
    "            out_df = out_df.join(already_default,on='uuid',how='left')\n",
    "            out_df = out_df.join(sum_amount,on='uuid',how='left',rsuffix='_sum')\n",
    "            out_df = out_df.join(count_loans,on='uuid',how='left',rsuffix='_count')\n",
    "            out_df.columns = ['uuid','target','sum_amount','count_loans']\n",
    "            return out_df\n",
    "        \n",
    "    def __feature_eng_recharges(self,df_r: pd.DataFrame) -> pd.DataFrame:\n",
    "        '''\n",
    "        Feature engineering for recharges dataframe using historical data\n",
    "        freq_recharges_weekly: mean frequency recharges per week\n",
    "        recharges_weekly: median frequency recharges per week\n",
    "        delta_after_recharge: difference between balance after recharge and recharge value\n",
    "\n",
    "        :param df_r: recharges dataframe\n",
    "        :return: feature engineered recharges dataframe\n",
    "        '''\n",
    "        df_r['delta_after_recharge'] = df_r['balance_after_recharge'] - df_r['recharge_value']\n",
    "        df_r['back_recharge_timestamp'] = pd.to_datetime(df_r['recharge_timestamp']) - pd.to_timedelta(7, unit='d')\n",
    "        max_date = df_r['back_recharge_timestamp'].max()\n",
    "        min_date = df_r['back_recharge_timestamp'].min()\n",
    "        count_weeks = (max_date - min_date).days // 7\n",
    "        weekly_df = df_r \\\n",
    "            .groupby(['uuid', pd.Grouper(key='recharge_timestamp', freq='W-MON')]) \\\n",
    "            .count() \\\n",
    "            .groupby('uuid')\n",
    "        \n",
    "        freq_recharges_weekly = weekly_df.sum()['recharge_value']/count_weeks\n",
    "        recharges_weekly = weekly_df.median()['recharge_value']/count_weeks\n",
    "        delta_after_recharges = df_r.groupby('uuid').median()['delta_after_recharge']\n",
    "        \n",
    "        out_df = pd.DataFrame(df_r.groupby('uuid').count().index)\n",
    "        out_df = out_df.join(freq_recharges_weekly,on='uuid',how='left',rsuffix='_median')\n",
    "        out_df = out_df.join(recharges_weekly,on='uuid',how='left',rsuffix='_median')\n",
    "        out_df = out_df.join(delta_after_recharges,on='uuid',how='left')\n",
    "        out_df.columns = ['uuid','freq_recharges_weekly','recharges_weekly','delta_after_recharges']\n",
    "        return out_df\n",
    "\n",
    "    @staticmethod\n",
    "    def remove_perfect_correlation(df: pd.DataFrame,max_cor = 0.95) -> pd.DataFrame:\n",
    "        ''''\n",
    "        Remove columns with perfect correlation with other columns\n",
    "        :param df: dataframe\n",
    "        :return: dataframe without columns with perfect correlation\n",
    "        \n",
    "        corr_matrix = df.corr()\n",
    "        corr_matrix.loc[:, :] = np.tril(corr_matrix.values, k=-1)\n",
    "        cols_to_drop = corr_matrix.loc[:,(corr_matrix.abs() > max_cor).any()]\n",
    "        print((corr_matrix.abs() > max_cor).any())\n",
    "        df = df.drop(cols_to_drop,axis=1)\n",
    "        TODO\n",
    "        '''\n",
    "        df = df.drop('count_loans',axis=1)\n",
    "        return df\n",
    "\n",
    "@dataclass\n",
    "class ForecastDefault:\n",
    "    '''\n",
    "    docstring\n",
    "    '''\n",
    "    loans_hist: pd.DataFrame\n",
    "    recharges_hist: pd.DataFrame\n",
    "    estimators_list: List\n",
    "    inicial_date: str = '2000-01-01'\n",
    "    limit_date: str = '2019-12-05'\n",
    "    days_to_default: int = 60\n",
    "    fill_na:bool = True\n",
    "\n",
    "    def __post_init__(self):\n",
    "        date_format = '%Y-%m-%d'\n",
    "        self.inicial_date = datetime.strptime(self.inicial_date,date_format)\n",
    "        self.limit_date = datetime.strptime(self.limit_date,date_format)\n",
    "        self.loans_hist['paid_at'] = self.loans_hist['paid_at'].fillna(self.limit_date + timedelta(days=1))\n",
    "        last_date = self.limit_date - timedelta(days=self.days_to_default)\n",
    "        \n",
    "\n",
    "        self.loans = self.loans_hist[self.loans_hist['created_at'] > self.inicial_date].copy()\n",
    "        self.recharges = self.recharges_hist[self.recharges_hist['recharge_timestamp'] > self.inicial_date].copy()\n",
    "        \n",
    "\n",
    "        train_loans = self.loans[self.loans['created_at'] < last_date]\n",
    "        test_loans = self.loans[((self.loans['created_at'] > last_date) & (self.loans['created_at'] < self.limit_date))]\n",
    "        train_recharges = self.recharges[self.recharges['recharge_timestamp'] < last_date]\n",
    "        \n",
    "        print('last_date',last_date)\n",
    "        print('limit_date',test_loans['created_at'].max())\n",
    "\n",
    "        \n",
    "        print('train_loans: ',train_loans.shape)\n",
    "        print('test_loans: ',test_loans.shape)\n",
    "\n",
    "\n",
    "        fe = FeatureEngineering(train_loans,test_loans,train_recharges,days_to_default=self.days_to_default)\n",
    "\n",
    "        train_df = fe.train_loans.merge(fe.train_recharges, on='uuid', how='left')\n",
    "        train_df = fe.remove_perfect_correlation(train_df)\n",
    "\n",
    "        if self.fill_na:\n",
    "            train_df.fillna(0,inplace=True)\n",
    "\n",
    "        self.model = FitModel(train_df,fe.test_loans[['uuid','target']],self.estimators_list)\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "@dataclass\n",
    "class FitModel:\n",
    "    '''\n",
    "    Class to fit the model\n",
    "    :param train_df: dataframe with training data\n",
    "    :param fe_test_df: dataframe containing forward targets to evaluate performance metrics\n",
    "    :param estimator_list: list of estimators to use in the model\n",
    "    '''\n",
    "    train_df: pd.DataFrame\n",
    "    fe_test_df: pd.DataFrame\n",
    "    estimators_list: List\n",
    "\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.train_X, self.train_y = self.__under_sampling(self.train_df.copy())\n",
    "        self.test_df = self.train_X.merge(self.fe_test_df,on='uuid',how='inner')\n",
    "        \n",
    "\n",
    "        self.train_X.drop('uuid',axis=1,inplace=True)\n",
    "        self.test_df.drop('uuid',axis=1,inplace=True)\n",
    "\n",
    "        self.test_X = self.test_df.drop('target',axis=1)\n",
    "        self.test_y = self.test_df['target']\n",
    "\n",
    "        print('train_X: ',self.train_X.shape)\n",
    "        print('train_y: ',self.train_y.shape)\n",
    "                \n",
    "\n",
    "        #Vai mudar para aceitar varios estimadores mas agora vai sobreescrever o modelo\n",
    "        for est in self.estimators_list:\n",
    "            self.est = self.__fit(est)\n",
    "\n",
    "\n",
    "        self.evaluate_model()\n",
    "        \n",
    "    def evaluate_model(self):\n",
    "        print('Confusion Matrix: \\n',confusion_matrix(self.test_y, self.predict(self.test_X)))\n",
    "        print('Classification Report: \\n',classification_report(self.test_y, self.predict(self.test_X)))\n",
    "    \n",
    "    def predict(self,X: pd.DataFrame) -> pd.Series:\n",
    "        '''\n",
    "        Predict using the fitted model\n",
    "        :param X: dataframe with features\n",
    "        :return: predictions\n",
    "        '''\n",
    "        #pred_df = pd.DataFrame(X.index)\n",
    "        #pred_df['default_probability'] = self.est.predict(X)\n",
    "        pred_df = self.est.predict(X)\n",
    "        return pred_df\n",
    "\n",
    "\n",
    "    def __fit(self,estimator):\n",
    "        '''\n",
    "        docstring\n",
    "        '''\n",
    "        est = estimator()\n",
    "        est.fit(self.train_X, self.train_y)\n",
    "        return est\n",
    "\n",
    "    \n",
    "    def __under_sampling(self,df: pd.DataFrame) -> pd.DataFrame:\n",
    "        '''\n",
    "        Under sampling of dataframe\n",
    "        :param df: dataframe\n",
    "        :return: undersampled dataframe\n",
    "        '''\n",
    "        rus = RandomUnderSampler(random_state=42)\n",
    "        train_X, train_y = rus.fit_resample(\n",
    "            train_df.drop(['target'],axis=1),train_df['target'])\n",
    "        return train_X, train_y\n",
    "\n",
    "\n",
    "\n",
    "s = ForecastDefault(loans_hist=loans, recharges_hist=recharges, estimators_list=[RandomForestClassifier],inicial_date='2019-01-01',days_to_default=1,limit_date='2019-12-05')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NULLS : uuid                      0\n",
      "target                    0\n",
      "sum_amount               79\n",
      "count_loans              79\n",
      "freq_recharges_weekly    34\n",
      "recharges_weekly         34\n",
      "delta_after_recharges    34\n",
      "dtype: int64\n",
      "NA FILLED : uuid                     0\n",
      "target                   0\n",
      "sum_amount               0\n",
      "count_loans              0\n",
      "freq_recharges_weekly    0\n",
      "recharges_weekly         0\n",
      "delta_after_recharges    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "PREDICT_FORWARD_DAYS = 60\n",
    "last_date = loans['created_at'].max() - timedelta(days=60)\n",
    "recharges['delta_after_recharge'] = recharges['balance_after_recharge'] - recharges['recharge_value']\n",
    "loans['paid_days_interval'] = (loans['paid_at'] - loans['created_at']).dt.days.fillna(61)\n",
    "loans['target'] = loans['paid_days_interval'].apply(lambda x: 1 if x > 60 else 0)\n",
    "\n",
    "train_loans = loans[loans['created_at'] < last_date].copy()\n",
    "test_loans = loans[loans['created_at'] > last_date].copy()\n",
    "\n",
    "\n",
    "train_recharges = recharges[recharges['recharge_timestamp'] < last_date].copy()\n",
    "test_recharges = recharges[recharges['recharge_timestamp'] > last_date].copy()\n",
    "\n",
    "\n",
    "def feature_eng_loans(loans_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    '''\n",
    "    Feature engineering for loans dataframe using historical data\n",
    "    already_default: 0 if not defaulted, 1 if defaulted\n",
    "    sum_amoun: sum amount of all previous loans paid\n",
    "    count_loans: number of previous loans paid\n",
    "    '''\n",
    "    already_default = loans_df.groupby('uuid').sum()['target'].apply(lambda x: 1 if x > 0 else 0)\n",
    "    sum_amount = loans_df.query('target == 0').groupby('uuid').sum()['amount']\n",
    "    count_loans = loans_df.query('target == 0').groupby('uuid').count()['amount']\n",
    "\n",
    "    out_df = pd.DataFrame(loans_df.groupby('uuid').count().index)\n",
    "    out_df = out_df.join(already_default,on='uuid',how='left')\n",
    "    out_df = out_df.join(sum_amount,on='uuid',how='left',rsuffix='_sum')\n",
    "    out_df = out_df.join(count_loans,on='uuid',how='left',rsuffix='_count')\n",
    "    out_df.columns = ['uuid','target','sum_amount','count_loans']\n",
    "    return out_df\n",
    "\n",
    "def feature_eng_recharges(recharges_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    '''\n",
    "    Feature engineering for recharges dataframe using historical data\n",
    "    freq_recharges_weekly: mean frequency recharges per week\n",
    "    recharges_weekly: median frequency recharges per week\n",
    "    delta_after_recharge: difference between balance after recharge and recharge value\n",
    "    '''\n",
    "    recharges_df['back_recharge_timestamp'] = pd.to_datetime(recharges_df['recharge_timestamp']) - pd.to_timedelta(7, unit='d')\n",
    "    max_date = recharges_df['back_recharge_timestamp'].max()\n",
    "    min_date = recharges_df['back_recharge_timestamp'].min()\n",
    "    count_weeks = (max_date - min_date).days // 7\n",
    "    weekly_df = recharges_df \\\n",
    "        .groupby(['uuid', pd.Grouper(key='recharge_timestamp', freq='W-MON')]) \\\n",
    "        .count() \\\n",
    "        .groupby('uuid')\n",
    "    \n",
    "    freq_recharges_weekly = weekly_df.sum()['recharge_value']/count_weeks\n",
    "    recharges_weekly = weekly_df.median()['recharge_value']/count_weeks\n",
    "    delta_after_recharges = recharges_df.groupby('uuid').median()['delta_after_recharge']\n",
    "    \n",
    "    out_df = pd.DataFrame(recharges_df.groupby('uuid').count().index)\n",
    "    out_df = out_df.join(freq_recharges_weekly,on='uuid',how='left',rsuffix='_median')\n",
    "    out_df = out_df.join(recharges_weekly,on='uuid',how='left',rsuffix='_median')\n",
    "    out_df = out_df.join(delta_after_recharges,on='uuid',how='left')\n",
    "    out_df.columns = ['uuid','freq_recharges_weekly','recharges_weekly','delta_after_recharges']\n",
    "    return out_df\n",
    "\n",
    "test_loans_fe = feature_eng_loans(test_loans)\n",
    "\n",
    "train_loans_fe = feature_eng_loans(train_loans)\n",
    "train_recharges_fe = feature_eng_recharges(train_recharges)\n",
    "train_df = train_loans_fe.merge(train_recharges_fe,on='uuid',how='left')\n",
    "\n",
    "#check nulls\n",
    "print('NULLS :',train_df.isnull().sum())\n",
    "train_df.fillna(0,inplace=True)\n",
    "print('NA FILLED :',train_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>sum_amount</th>\n",
       "      <th>count_loans</th>\n",
       "      <th>freq_recharges_weekly</th>\n",
       "      <th>recharges_weekly</th>\n",
       "      <th>delta_after_recharges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1033.000000</td>\n",
       "      <td>1033.000000</td>\n",
       "      <td>1033.000000</td>\n",
       "      <td>1033.000000</td>\n",
       "      <td>1033.000000</td>\n",
       "      <td>1033.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.115198</td>\n",
       "      <td>12.662149</td>\n",
       "      <td>2.323330</td>\n",
       "      <td>0.956559</td>\n",
       "      <td>0.170196</td>\n",
       "      <td>0.541723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.319416</td>\n",
       "      <td>14.921600</td>\n",
       "      <td>2.280692</td>\n",
       "      <td>0.824489</td>\n",
       "      <td>0.087977</td>\n",
       "      <td>0.964410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.075000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.285000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.670000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>20.050000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            target   sum_amount  count_loans  freq_recharges_weekly  \\\n",
       "count  1033.000000  1033.000000  1033.000000            1033.000000   \n",
       "mean      0.115198    12.662149     2.323330               0.956559   \n",
       "std       0.319416    14.921600     2.280692               0.824489   \n",
       "min       0.000000     0.000000     0.000000               0.000000   \n",
       "25%       0.000000     5.000000     1.000000               0.375000   \n",
       "50%       0.000000    10.000000     2.000000               0.750000   \n",
       "75%       0.000000    15.000000     3.000000               1.250000   \n",
       "max       1.000000   150.000000    20.000000               5.500000   \n",
       "\n",
       "       recharges_weekly  delta_after_recharges  \n",
       "count       1033.000000            1033.000000  \n",
       "mean           0.170196               0.541723  \n",
       "std            0.087977               0.964410  \n",
       "min            0.000000               0.000000  \n",
       "25%            0.125000               0.075000  \n",
       "50%            0.125000               0.285000  \n",
       "75%            0.250000               0.670000  \n",
       "max            0.812500              20.050000  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>sum_amount</th>\n",
       "      <th>count_loans</th>\n",
       "      <th>freq_recharges_weekly</th>\n",
       "      <th>recharges_weekly</th>\n",
       "      <th>delta_after_recharges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.231116</td>\n",
       "      <td>-0.269322</td>\n",
       "      <td>-0.290510</td>\n",
       "      <td>-0.211319</td>\n",
       "      <td>-0.088737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sum_amount</th>\n",
       "      <td>-0.231116</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.975378</td>\n",
       "      <td>0.647190</td>\n",
       "      <td>0.485158</td>\n",
       "      <td>0.100453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count_loans</th>\n",
       "      <td>-0.269322</td>\n",
       "      <td>0.975378</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.638603</td>\n",
       "      <td>0.464965</td>\n",
       "      <td>0.101892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq_recharges_weekly</th>\n",
       "      <td>-0.290510</td>\n",
       "      <td>0.647190</td>\n",
       "      <td>0.638603</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.712777</td>\n",
       "      <td>0.085745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recharges_weekly</th>\n",
       "      <td>-0.211319</td>\n",
       "      <td>0.485158</td>\n",
       "      <td>0.464965</td>\n",
       "      <td>0.712777</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.127432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>delta_after_recharges</th>\n",
       "      <td>-0.088737</td>\n",
       "      <td>0.100453</td>\n",
       "      <td>0.101892</td>\n",
       "      <td>0.085745</td>\n",
       "      <td>0.127432</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         target  sum_amount  count_loans  \\\n",
       "target                 1.000000   -0.231116    -0.269322   \n",
       "sum_amount            -0.231116    1.000000     0.975378   \n",
       "count_loans           -0.269322    0.975378     1.000000   \n",
       "freq_recharges_weekly -0.290510    0.647190     0.638603   \n",
       "recharges_weekly      -0.211319    0.485158     0.464965   \n",
       "delta_after_recharges -0.088737    0.100453     0.101892   \n",
       "\n",
       "                       freq_recharges_weekly  recharges_weekly  \\\n",
       "target                             -0.290510         -0.211319   \n",
       "sum_amount                          0.647190          0.485158   \n",
       "count_loans                         0.638603          0.464965   \n",
       "freq_recharges_weekly               1.000000          0.712777   \n",
       "recharges_weekly                    0.712777          1.000000   \n",
       "delta_after_recharges               0.085745          0.127432   \n",
       "\n",
       "                       delta_after_recharges  \n",
       "target                             -0.088737  \n",
       "sum_amount                          0.100453  \n",
       "count_loans                         0.101892  \n",
       "freq_recharges_weekly               0.085745  \n",
       "recharges_weekly                    0.127432  \n",
       "delta_after_recharges               1.000000  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SMOTE oversampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "df_tmp = train_df.reset_index()\n",
    "df_tmp['index'] = le.fit_transform(df_tmp['uuid'])\n",
    "train_X,train_y = oversample.fit_resample(\n",
    "    df_tmp.drop(['uuid','target'],axis=1),\n",
    "    df_tmp[['target']])\n",
    "train_X['uuid'] = le.inverse_transform(train_X['index'])\n",
    "train_X.set_index('uuid')\n",
    "train_X.drop('index',axis=1,inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "test_df = train_X.merge(test_loans_fe[['uuid','target']],on='uuid',how='inner')\n",
    "train_X.drop('uuid',axis=1,inplace=True)\n",
    "test_df.drop('uuid',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "under_sampler = RandomUnderSampler(random_state=2022)\n",
    "train_X, train_y = under_sampler.fit_resample(\n",
    "    train_df.drop(['target'],axis=1),\n",
    "    train_df[['target']])\n",
    "\n",
    "test_df = train_X.merge(test_loans_fe[['uuid','target']],on='uuid',how='inner')\n",
    "train_X.drop('uuid',axis=1,inplace=True)\n",
    "test_df.drop('uuid',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "238"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(s.sample_indices_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lembrar de fazer o a otimização dos parametros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Com multicolinearidade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5966386554621849\n",
      "Confusion Matrix: \n",
      " [[118  66]\n",
      " [ 30  24]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.64      0.71       184\n",
      "           1       0.27      0.44      0.33        54\n",
      "\n",
      "    accuracy                           0.60       238\n",
      "   macro avg       0.53      0.54      0.52       238\n",
      "weighted avg       0.68      0.60      0.63       238\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_46910/3595253554.py:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rfc.fit(train_X, train_y)\n"
     ]
    }
   ],
   "source": [
    "#fit classification model on t_df random forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=100, max_depth=3, random_state=2022)\n",
    "rfc.fit(train_X, train_y)\n",
    "y_pred = rfc.predict(test_df.drop(['target'],axis=1))\n",
    "print('Accuracy: ',accuracy_score(test_df['target'], y_pred))\n",
    "print('Confusion Matrix: \\n',confusion_matrix(test_df['target'], y_pred))\n",
    "print('Classification Report: \\n',classification_report(test_df['target'], y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sem multicolinearidade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sum_amount</th>\n",
       "      <th>count_loans</th>\n",
       "      <th>freq_recharges_weekly</th>\n",
       "      <th>recharges_weekly</th>\n",
       "      <th>delta_after_recharges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sum_amount</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.966692</td>\n",
       "      <td>0.652630</td>\n",
       "      <td>0.477287</td>\n",
       "      <td>0.219949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count_loans</th>\n",
       "      <td>0.966692</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.653344</td>\n",
       "      <td>0.466286</td>\n",
       "      <td>0.242840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq_recharges_weekly</th>\n",
       "      <td>0.652630</td>\n",
       "      <td>0.653344</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.731600</td>\n",
       "      <td>0.215462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recharges_weekly</th>\n",
       "      <td>0.477287</td>\n",
       "      <td>0.466286</td>\n",
       "      <td>0.731600</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.266321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>delta_after_recharges</th>\n",
       "      <td>0.219949</td>\n",
       "      <td>0.242840</td>\n",
       "      <td>0.215462</td>\n",
       "      <td>0.266321</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       sum_amount  count_loans  freq_recharges_weekly  \\\n",
       "sum_amount               1.000000     0.966692               0.652630   \n",
       "count_loans              0.966692     1.000000               0.653344   \n",
       "freq_recharges_weekly    0.652630     0.653344               1.000000   \n",
       "recharges_weekly         0.477287     0.466286               0.731600   \n",
       "delta_after_recharges    0.219949     0.242840               0.215462   \n",
       "\n",
       "                       recharges_weekly  delta_after_recharges  \n",
       "sum_amount                     0.477287               0.219949  \n",
       "count_loans                    0.466286               0.242840  \n",
       "freq_recharges_weekly          0.731600               0.215462  \n",
       "recharges_weekly               1.000000               0.266321  \n",
       "delta_after_recharges          0.266321               1.000000  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5504201680672269\n",
      "Confusion Matrix: \n",
      " [[97 87]\n",
      " [20 34]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.53      0.64       184\n",
      "           1       0.28      0.63      0.39        54\n",
      "\n",
      "    accuracy                           0.55       238\n",
      "   macro avg       0.56      0.58      0.52       238\n",
      "weighted avg       0.70      0.55      0.59       238\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_46910/3043307356.py:10: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rfc.fit(train_X.drop('count_loans',axis=1), train_y)\n"
     ]
    }
   ],
   "source": [
    "#fit classification model on t_df random forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "#Ajust the model to pipeline\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(train_X.drop('count_loans',axis=1), train_y)\n",
    "y_pred = rfc.predict(test_df.drop(['count_loans','target'],axis=1))\n",
    "print('Accuracy: ',accuracy_score(test_df['target'], y_pred))\n",
    "print('Confusion Matrix: \\n',confusion_matrix(test_df['target'], y_pred))\n",
    "print('Classification Report: \\n',classification_report(test_df['target'], y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "All intermediate steps should be transformers and implement fit and transform or be the string 'passthrough' 'RandomForestClassifier(max_depth=3, random_state=2022)' (type <class 'sklearn.ensemble._forest.RandomForestClassifier'>) doesn't",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/enniobastos/Documents/projects/portfolio/Juvo/0_load_data.ipynb Cell 20'\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/enniobastos/Documents/projects/portfolio/Juvo/0_load_data.ipynb#ch0000024?line=6'>7</a>\u001b[0m train_X\u001b[39m.\u001b[39mdrop(\u001b[39m'\u001b[39m\u001b[39muuid\u001b[39m\u001b[39m'\u001b[39m,axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/enniobastos/Documents/projects/portfolio/Juvo/0_load_data.ipynb#ch0000024?line=7'>8</a>\u001b[0m test_df\u001b[39m.\u001b[39mdrop(\u001b[39m'\u001b[39m\u001b[39muuid\u001b[39m\u001b[39m'\u001b[39m,axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/enniobastos/Documents/projects/portfolio/Juvo/0_load_data.ipynb#ch0000024?line=9'>10</a>\u001b[0m pipeline \u001b[39m=\u001b[39m Pipeline([\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/enniobastos/Documents/projects/portfolio/Juvo/0_load_data.ipynb#ch0000024?line=10'>11</a>\u001b[0m (\u001b[39m'\u001b[39;49m\u001b[39mrfc\u001b[39;49m\u001b[39m'\u001b[39;49m, RandomForestClassifier(n_estimators\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m, max_depth\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m, random_state\u001b[39m=\u001b[39;49m\u001b[39m2022\u001b[39;49m)),\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/enniobastos/Documents/projects/portfolio/Juvo/0_load_data.ipynb#ch0000024?line=11'>12</a>\u001b[0m (\u001b[39m'\u001b[39;49m\u001b[39munder_sampler\u001b[39;49m\u001b[39m'\u001b[39;49m, RandomUnderSampler(random_state\u001b[39m=\u001b[39;49m\u001b[39m2022\u001b[39;49m)),\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/enniobastos/Documents/projects/portfolio/Juvo/0_load_data.ipynb#ch0000024?line=12'>13</a>\u001b[0m ])\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/enniobastos/Documents/projects/portfolio/Juvo/0_load_data.ipynb#ch0000024?line=13'>14</a>\u001b[0m pipeline\u001b[39m.\u001b[39mfit(train_X, train_y)\n",
      "File \u001b[0;32m~/miniconda3/envs/juvo_test_pycaret/lib/python3.8/site-packages/sklearn/utils/validation.py:72\u001b[0m, in \u001b[0;36m_deprecate_positional_args.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\u001b[39m\"\u001b[39m\u001b[39mPass \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m as keyword args. From version 0.25 \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     68\u001b[0m                   \u001b[39m\"\u001b[39m\u001b[39mpassing these as positional arguments will \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     69\u001b[0m                   \u001b[39m\"\u001b[39m\u001b[39mresult in an error\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(args_msg)),\n\u001b[1;32m     70\u001b[0m                   \u001b[39mFutureWarning\u001b[39;00m)\n\u001b[1;32m     71\u001b[0m kwargs\u001b[39m.\u001b[39mupdate({k: arg \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args)})\n\u001b[0;32m---> 72\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/juvo_test_pycaret/lib/python3.8/site-packages/sklearn/pipeline.py:114\u001b[0m, in \u001b[0;36mPipeline.__init__\u001b[0;34m(self, steps, memory, verbose)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmemory \u001b[39m=\u001b[39m memory\n\u001b[1;32m    113\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m=\u001b[39m verbose\n\u001b[0;32m--> 114\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_steps()\n",
      "File \u001b[0;32m~/miniconda3/envs/juvo_test_pycaret/lib/python3.8/site-packages/sklearn/pipeline.py:159\u001b[0m, in \u001b[0;36mPipeline._validate_steps\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m    157\u001b[0m     \u001b[39mif\u001b[39;00m (\u001b[39mnot\u001b[39;00m (\u001b[39mhasattr\u001b[39m(t, \u001b[39m\"\u001b[39m\u001b[39mfit\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mor\u001b[39;00m \u001b[39mhasattr\u001b[39m(t, \u001b[39m\"\u001b[39m\u001b[39mfit_transform\u001b[39m\u001b[39m\"\u001b[39m)) \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m\n\u001b[1;32m    158\u001b[0m             \u001b[39mhasattr\u001b[39m(t, \u001b[39m\"\u001b[39m\u001b[39mtransform\u001b[39m\u001b[39m\"\u001b[39m)):\n\u001b[0;32m--> 159\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mAll intermediate steps should be \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    160\u001b[0m                         \u001b[39m\"\u001b[39m\u001b[39mtransformers and implement fit and transform \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    161\u001b[0m                         \u001b[39m\"\u001b[39m\u001b[39mor be the string \u001b[39m\u001b[39m'\u001b[39m\u001b[39mpassthrough\u001b[39m\u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    162\u001b[0m                         \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m (type \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m) doesn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (t, \u001b[39mtype\u001b[39m(t)))\n\u001b[1;32m    164\u001b[0m \u001b[39m# We allow last estimator to be None as an identity transformation\u001b[39;00m\n\u001b[1;32m    165\u001b[0m \u001b[39mif\u001b[39;00m (estimator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m estimator \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mpassthrough\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    166\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(estimator, \u001b[39m\"\u001b[39m\u001b[39mfit\u001b[39m\u001b[39m\"\u001b[39m)):\n",
      "\u001b[0;31mTypeError\u001b[0m: All intermediate steps should be transformers and implement fit and transform or be the string 'passthrough' 'RandomForestClassifier(max_depth=3, random_state=2022)' (type <class 'sklearn.ensemble._forest.RandomForestClassifier'>) doesn't"
     ]
    }
   ],
   "source": [
    "under_sampler = RandomUnderSampler(random_state=2022)\n",
    "train_X, train_y = under_sampler.fit_resample(\n",
    "train_df.drop(['target'],axis=1),\n",
    "train_df[['target']])\n",
    "\n",
    "test_df = train_X.merge(test_loans_fe[['uuid','target']],on='uuid',how='inner')\n",
    "train_X.drop('uuid',axis=1,inplace=True)\n",
    "test_df.drop('uuid',axis=1,inplace=True)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "('rfc', RandomForestClassifier(n_estimators=100, max_depth=3, random_state=2022)),\n",
    "('under_sampler', RandomUnderSampler(random_state=2022)),\n",
    "])\n",
    "pipeline.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pycaret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_a06c9_row44_col1 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_a06c9\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_a06c9_level0_col0\" class=\"col_heading level0 col0\" >Description</th>\n",
       "      <th id=\"T_a06c9_level0_col1\" class=\"col_heading level0 col1\" >Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_a06c9_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_a06c9_row0_col0\" class=\"data row0 col0\" >session_id</td>\n",
       "      <td id=\"T_a06c9_row0_col1\" class=\"data row0 col1\" >6788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a06c9_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_a06c9_row1_col0\" class=\"data row1 col0\" >Target</td>\n",
       "      <td id=\"T_a06c9_row1_col1\" class=\"data row1 col1\" >target</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a06c9_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_a06c9_row2_col0\" class=\"data row2 col0\" >Target Type</td>\n",
       "      <td id=\"T_a06c9_row2_col1\" class=\"data row2 col1\" >Binary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a06c9_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_a06c9_row3_col0\" class=\"data row3 col0\" >Label Encoded</td>\n",
       "      <td id=\"T_a06c9_row3_col1\" class=\"data row3 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a06c9_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_a06c9_row4_col0\" class=\"data row4 col0\" >Original Data</td>\n",
       "      <td id=\"T_a06c9_row4_col1\" class=\"data row4 col1\" >(238, 6)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a06c9_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_a06c9_row5_col0\" class=\"data row5 col0\" >Missing Values</td>\n",
       "      <td id=\"T_a06c9_row5_col1\" class=\"data row5 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a06c9_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_a06c9_row6_col0\" class=\"data row6 col0\" >Numeric Features</td>\n",
       "      <td id=\"T_a06c9_row6_col1\" class=\"data row6 col1\" >5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a06c9_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_a06c9_row7_col0\" class=\"data row7 col0\" >Categorical Features</td>\n",
       "      <td id=\"T_a06c9_row7_col1\" class=\"data row7 col1\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a06c9_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_a06c9_row8_col0\" class=\"data row8 col0\" >Ordinal Features</td>\n",
       "      <td id=\"T_a06c9_row8_col1\" class=\"data row8 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a06c9_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_a06c9_row9_col0\" class=\"data row9 col0\" >High Cardinality Features</td>\n",
       "      <td id=\"T_a06c9_row9_col1\" class=\"data row9 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a06c9_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_a06c9_row10_col0\" class=\"data row10 col0\" >High Cardinality Method</td>\n",
       "      <td id=\"T_a06c9_row10_col1\" class=\"data row10 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a06c9_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_a06c9_row11_col0\" class=\"data row11 col0\" >Transformed Train Set</td>\n",
       "      <td id=\"T_a06c9_row11_col1\" class=\"data row11 col1\" >(166, 5)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a06c9_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_a06c9_row12_col0\" class=\"data row12 col0\" >Transformed Test Set</td>\n",
       "      <td id=\"T_a06c9_row12_col1\" class=\"data row12 col1\" >(72, 5)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a06c9_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_a06c9_row13_col0\" class=\"data row13 col0\" >Shuffle Train-Test</td>\n",
       "      <td id=\"T_a06c9_row13_col1\" class=\"data row13 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a06c9_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_a06c9_row14_col0\" class=\"data row14 col0\" >Stratify Train-Test</td>\n",
       "      <td id=\"T_a06c9_row14_col1\" class=\"data row14 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a06c9_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_a06c9_row15_col0\" class=\"data row15 col0\" >Fold Generator</td>\n",
       "      <td id=\"T_a06c9_row15_col1\" class=\"data row15 col1\" >StratifiedKFold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a06c9_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_a06c9_row16_col0\" class=\"data row16 col0\" >Fold Number</td>\n",
       "      <td id=\"T_a06c9_row16_col1\" class=\"data row16 col1\" >10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a06c9_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_a06c9_row17_col0\" class=\"data row17 col0\" >CPU Jobs</td>\n",
       "      <td id=\"T_a06c9_row17_col1\" class=\"data row17 col1\" >-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a06c9_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_a06c9_row18_col0\" class=\"data row18 col0\" >Use GPU</td>\n",
       "      <td id=\"T_a06c9_row18_col1\" class=\"data row18 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a06c9_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "      <td id=\"T_a06c9_row19_col0\" class=\"data row19 col0\" >Log Experiment</td>\n",
       "      <td id=\"T_a06c9_row19_col1\" class=\"data row19 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a06c9_level0_row20\" class=\"row_heading level0 row20\" >20</th>\n",
       "      <td id=\"T_a06c9_row20_col0\" class=\"data row20 col0\" >Experiment Name</td>\n",
       "      <td id=\"T_a06c9_row20_col1\" class=\"data row20 col1\" >clf-default-name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a06c9_level0_row21\" class=\"row_heading level0 row21\" >21</th>\n",
       "      <td id=\"T_a06c9_row21_col0\" class=\"data row21 col0\" >USI</td>\n",
       "      <td id=\"T_a06c9_row21_col1\" class=\"data row21 col1\" >8a97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a06c9_level0_row22\" class=\"row_heading level0 row22\" >22</th>\n",
       "      <td id=\"T_a06c9_row22_col0\" class=\"data row22 col0\" >Imputation Type</td>\n",
       "      <td id=\"T_a06c9_row22_col1\" class=\"data row22 col1\" >simple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a06c9_level0_row23\" class=\"row_heading level0 row23\" >23</th>\n",
       "      <td id=\"T_a06c9_row23_col0\" class=\"data row23 col0\" >Iterative Imputation Iteration</td>\n",
       "      <td id=\"T_a06c9_row23_col1\" class=\"data row23 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a06c9_level0_row24\" class=\"row_heading level0 row24\" >24</th>\n",
       "      <td id=\"T_a06c9_row24_col0\" class=\"data row24 col0\" >Numeric Imputer</td>\n",
       "      <td id=\"T_a06c9_row24_col1\" class=\"data row24 col1\" >mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a06c9_level0_row25\" class=\"row_heading level0 row25\" >25</th>\n",
       "      <td id=\"T_a06c9_row25_col0\" class=\"data row25 col0\" >Iterative Imputation Numeric Model</td>\n",
       "      <td id=\"T_a06c9_row25_col1\" class=\"data row25 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a06c9_level0_row26\" class=\"row_heading level0 row26\" >26</th>\n",
       "      <td id=\"T_a06c9_row26_col0\" class=\"data row26 col0\" >Categorical Imputer</td>\n",
       "      <td id=\"T_a06c9_row26_col1\" class=\"data row26 col1\" >constant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a06c9_level0_row27\" class=\"row_heading level0 row27\" >27</th>\n",
       "      <td id=\"T_a06c9_row27_col0\" class=\"data row27 col0\" >Iterative Imputation Categorical Model</td>\n",
       "      <td id=\"T_a06c9_row27_col1\" class=\"data row27 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a06c9_level0_row28\" class=\"row_heading level0 row28\" >28</th>\n",
       "      <td id=\"T_a06c9_row28_col0\" class=\"data row28 col0\" >Unknown Categoricals Handling</td>\n",
       "      <td id=\"T_a06c9_row28_col1\" class=\"data row28 col1\" >least_frequent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a06c9_level0_row29\" class=\"row_heading level0 row29\" >29</th>\n",
       "      <td id=\"T_a06c9_row29_col0\" class=\"data row29 col0\" >Normalize</td>\n",
       "      <td id=\"T_a06c9_row29_col1\" class=\"data row29 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a06c9_level0_row30\" class=\"row_heading level0 row30\" >30</th>\n",
       "      <td id=\"T_a06c9_row30_col0\" class=\"data row30 col0\" >Normalize Method</td>\n",
       "      <td id=\"T_a06c9_row30_col1\" class=\"data row30 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a06c9_level0_row31\" class=\"row_heading level0 row31\" >31</th>\n",
       "      <td id=\"T_a06c9_row31_col0\" class=\"data row31 col0\" >Transformation</td>\n",
       "      <td id=\"T_a06c9_row31_col1\" class=\"data row31 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a06c9_level0_row32\" class=\"row_heading level0 row32\" >32</th>\n",
       "      <td id=\"T_a06c9_row32_col0\" class=\"data row32 col0\" >Transformation Method</td>\n",
       "      <td id=\"T_a06c9_row32_col1\" class=\"data row32 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a06c9_level0_row33\" class=\"row_heading level0 row33\" >33</th>\n",
       "      <td id=\"T_a06c9_row33_col0\" class=\"data row33 col0\" >PCA</td>\n",
       "      <td id=\"T_a06c9_row33_col1\" class=\"data row33 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a06c9_level0_row34\" class=\"row_heading level0 row34\" >34</th>\n",
       "      <td id=\"T_a06c9_row34_col0\" class=\"data row34 col0\" >PCA Method</td>\n",
       "      <td id=\"T_a06c9_row34_col1\" class=\"data row34 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a06c9_level0_row35\" class=\"row_heading level0 row35\" >35</th>\n",
       "      <td id=\"T_a06c9_row35_col0\" class=\"data row35 col0\" >PCA Components</td>\n",
       "      <td id=\"T_a06c9_row35_col1\" class=\"data row35 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a06c9_level0_row36\" class=\"row_heading level0 row36\" >36</th>\n",
       "      <td id=\"T_a06c9_row36_col0\" class=\"data row36 col0\" >Ignore Low Variance</td>\n",
       "      <td id=\"T_a06c9_row36_col1\" class=\"data row36 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a06c9_level0_row37\" class=\"row_heading level0 row37\" >37</th>\n",
       "      <td id=\"T_a06c9_row37_col0\" class=\"data row37 col0\" >Combine Rare Levels</td>\n",
       "      <td id=\"T_a06c9_row37_col1\" class=\"data row37 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a06c9_level0_row38\" class=\"row_heading level0 row38\" >38</th>\n",
       "      <td id=\"T_a06c9_row38_col0\" class=\"data row38 col0\" >Rare Level Threshold</td>\n",
       "      <td id=\"T_a06c9_row38_col1\" class=\"data row38 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a06c9_level0_row39\" class=\"row_heading level0 row39\" >39</th>\n",
       "      <td id=\"T_a06c9_row39_col0\" class=\"data row39 col0\" >Numeric Binning</td>\n",
       "      <td id=\"T_a06c9_row39_col1\" class=\"data row39 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a06c9_level0_row40\" class=\"row_heading level0 row40\" >40</th>\n",
       "      <td id=\"T_a06c9_row40_col0\" class=\"data row40 col0\" >Remove Outliers</td>\n",
       "      <td id=\"T_a06c9_row40_col1\" class=\"data row40 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a06c9_level0_row41\" class=\"row_heading level0 row41\" >41</th>\n",
       "      <td id=\"T_a06c9_row41_col0\" class=\"data row41 col0\" >Outliers Threshold</td>\n",
       "      <td id=\"T_a06c9_row41_col1\" class=\"data row41 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a06c9_level0_row42\" class=\"row_heading level0 row42\" >42</th>\n",
       "      <td id=\"T_a06c9_row42_col0\" class=\"data row42 col0\" >Remove Multicollinearity</td>\n",
       "      <td id=\"T_a06c9_row42_col1\" class=\"data row42 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a06c9_level0_row43\" class=\"row_heading level0 row43\" >43</th>\n",
       "      <td id=\"T_a06c9_row43_col0\" class=\"data row43 col0\" >Multicollinearity Threshold</td>\n",
       "      <td id=\"T_a06c9_row43_col1\" class=\"data row43 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a06c9_level0_row44\" class=\"row_heading level0 row44\" >44</th>\n",
       "      <td id=\"T_a06c9_row44_col0\" class=\"data row44 col0\" >Remove Perfect Collinearity</td>\n",
       "      <td id=\"T_a06c9_row44_col1\" class=\"data row44 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a06c9_level0_row45\" class=\"row_heading level0 row45\" >45</th>\n",
       "      <td id=\"T_a06c9_row45_col0\" class=\"data row45 col0\" >Clustering</td>\n",
       "      <td id=\"T_a06c9_row45_col1\" class=\"data row45 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a06c9_level0_row46\" class=\"row_heading level0 row46\" >46</th>\n",
       "      <td id=\"T_a06c9_row46_col0\" class=\"data row46 col0\" >Clustering Iteration</td>\n",
       "      <td id=\"T_a06c9_row46_col1\" class=\"data row46 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a06c9_level0_row47\" class=\"row_heading level0 row47\" >47</th>\n",
       "      <td id=\"T_a06c9_row47_col0\" class=\"data row47 col0\" >Polynomial Features</td>\n",
       "      <td id=\"T_a06c9_row47_col1\" class=\"data row47 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a06c9_level0_row48\" class=\"row_heading level0 row48\" >48</th>\n",
       "      <td id=\"T_a06c9_row48_col0\" class=\"data row48 col0\" >Polynomial Degree</td>\n",
       "      <td id=\"T_a06c9_row48_col1\" class=\"data row48 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a06c9_level0_row49\" class=\"row_heading level0 row49\" >49</th>\n",
       "      <td id=\"T_a06c9_row49_col0\" class=\"data row49 col0\" >Trignometry Features</td>\n",
       "      <td id=\"T_a06c9_row49_col1\" class=\"data row49 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a06c9_level0_row50\" class=\"row_heading level0 row50\" >50</th>\n",
       "      <td id=\"T_a06c9_row50_col0\" class=\"data row50 col0\" >Polynomial Threshold</td>\n",
       "      <td id=\"T_a06c9_row50_col1\" class=\"data row50 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a06c9_level0_row51\" class=\"row_heading level0 row51\" >51</th>\n",
       "      <td id=\"T_a06c9_row51_col0\" class=\"data row51 col0\" >Group Features</td>\n",
       "      <td id=\"T_a06c9_row51_col1\" class=\"data row51 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a06c9_level0_row52\" class=\"row_heading level0 row52\" >52</th>\n",
       "      <td id=\"T_a06c9_row52_col0\" class=\"data row52 col0\" >Feature Selection</td>\n",
       "      <td id=\"T_a06c9_row52_col1\" class=\"data row52 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a06c9_level0_row53\" class=\"row_heading level0 row53\" >53</th>\n",
       "      <td id=\"T_a06c9_row53_col0\" class=\"data row53 col0\" >Feature Selection Method</td>\n",
       "      <td id=\"T_a06c9_row53_col1\" class=\"data row53 col1\" >classic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a06c9_level0_row54\" class=\"row_heading level0 row54\" >54</th>\n",
       "      <td id=\"T_a06c9_row54_col0\" class=\"data row54 col0\" >Features Selection Threshold</td>\n",
       "      <td id=\"T_a06c9_row54_col1\" class=\"data row54 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a06c9_level0_row55\" class=\"row_heading level0 row55\" >55</th>\n",
       "      <td id=\"T_a06c9_row55_col0\" class=\"data row55 col0\" >Feature Interaction</td>\n",
       "      <td id=\"T_a06c9_row55_col1\" class=\"data row55 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a06c9_level0_row56\" class=\"row_heading level0 row56\" >56</th>\n",
       "      <td id=\"T_a06c9_row56_col0\" class=\"data row56 col0\" >Feature Ratio</td>\n",
       "      <td id=\"T_a06c9_row56_col1\" class=\"data row56 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a06c9_level0_row57\" class=\"row_heading level0 row57\" >57</th>\n",
       "      <td id=\"T_a06c9_row57_col0\" class=\"data row57 col0\" >Interaction Threshold</td>\n",
       "      <td id=\"T_a06c9_row57_col1\" class=\"data row57 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a06c9_level0_row58\" class=\"row_heading level0 row58\" >58</th>\n",
       "      <td id=\"T_a06c9_row58_col0\" class=\"data row58 col0\" >Fix Imbalance</td>\n",
       "      <td id=\"T_a06c9_row58_col1\" class=\"data row58 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a06c9_level0_row59\" class=\"row_heading level0 row59\" >59</th>\n",
       "      <td id=\"T_a06c9_row59_col0\" class=\"data row59 col0\" >Fix Imbalance Method</td>\n",
       "      <td id=\"T_a06c9_row59_col1\" class=\"data row59 col1\" >SMOTE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f258d3db490>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pycaret.classification import *\n",
    "s = setup(data=pd.concat([train_X, train_y], axis=1), target = 'target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_82a17 th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_82a17_row0_col0, #T_82a17_row0_col2, #T_82a17_row0_col3, #T_82a17_row0_col4, #T_82a17_row1_col0, #T_82a17_row1_col1, #T_82a17_row1_col2, #T_82a17_row1_col3, #T_82a17_row1_col4, #T_82a17_row1_col5, #T_82a17_row1_col6, #T_82a17_row1_col7, #T_82a17_row2_col0, #T_82a17_row2_col1, #T_82a17_row2_col2, #T_82a17_row2_col3, #T_82a17_row2_col4, #T_82a17_row2_col5, #T_82a17_row2_col6, #T_82a17_row2_col7, #T_82a17_row3_col0, #T_82a17_row3_col1, #T_82a17_row3_col2, #T_82a17_row3_col3, #T_82a17_row3_col4, #T_82a17_row3_col5, #T_82a17_row3_col6, #T_82a17_row3_col7, #T_82a17_row4_col0, #T_82a17_row4_col1, #T_82a17_row4_col2, #T_82a17_row4_col3, #T_82a17_row4_col4, #T_82a17_row4_col5, #T_82a17_row4_col6, #T_82a17_row4_col7, #T_82a17_row5_col0, #T_82a17_row5_col1, #T_82a17_row5_col2, #T_82a17_row5_col3, #T_82a17_row5_col5, #T_82a17_row5_col6, #T_82a17_row5_col7, #T_82a17_row6_col0, #T_82a17_row6_col1, #T_82a17_row6_col3, #T_82a17_row6_col4, #T_82a17_row6_col5, #T_82a17_row6_col6, #T_82a17_row6_col7, #T_82a17_row7_col0, #T_82a17_row7_col1, #T_82a17_row7_col2, #T_82a17_row7_col3, #T_82a17_row7_col4, #T_82a17_row7_col5, #T_82a17_row7_col6, #T_82a17_row7_col7, #T_82a17_row8_col0, #T_82a17_row8_col1, #T_82a17_row8_col2, #T_82a17_row8_col3, #T_82a17_row8_col4, #T_82a17_row8_col5, #T_82a17_row8_col6, #T_82a17_row8_col7, #T_82a17_row9_col0, #T_82a17_row9_col1, #T_82a17_row9_col2, #T_82a17_row9_col3, #T_82a17_row9_col4, #T_82a17_row9_col5, #T_82a17_row9_col6, #T_82a17_row9_col7, #T_82a17_row10_col0, #T_82a17_row10_col1, #T_82a17_row10_col2, #T_82a17_row10_col3, #T_82a17_row10_col4, #T_82a17_row10_col5, #T_82a17_row10_col6, #T_82a17_row10_col7, #T_82a17_row11_col0, #T_82a17_row11_col1, #T_82a17_row11_col2, #T_82a17_row11_col3, #T_82a17_row11_col4, #T_82a17_row11_col5, #T_82a17_row11_col6, #T_82a17_row11_col7, #T_82a17_row12_col0, #T_82a17_row12_col1, #T_82a17_row12_col2, #T_82a17_row12_col4, #T_82a17_row12_col5, #T_82a17_row12_col6, #T_82a17_row12_col7, #T_82a17_row13_col0, #T_82a17_row13_col1, #T_82a17_row13_col2, #T_82a17_row13_col3, #T_82a17_row13_col4, #T_82a17_row13_col5, #T_82a17_row13_col6, #T_82a17_row13_col7 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_82a17_row0_col1, #T_82a17_row0_col5, #T_82a17_row0_col6, #T_82a17_row0_col7, #T_82a17_row5_col4, #T_82a17_row6_col2, #T_82a17_row12_col3 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "}\n",
       "#T_82a17_row0_col8, #T_82a17_row1_col8, #T_82a17_row2_col8, #T_82a17_row3_col8, #T_82a17_row5_col8, #T_82a17_row6_col8, #T_82a17_row8_col8, #T_82a17_row12_col8 {\n",
       "  text-align: left;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "#T_82a17_row4_col8, #T_82a17_row7_col8, #T_82a17_row9_col8, #T_82a17_row10_col8, #T_82a17_row11_col8, #T_82a17_row13_col8 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_82a17\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_82a17_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_82a17_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th id=\"T_82a17_level0_col2\" class=\"col_heading level0 col2\" >AUC</th>\n",
       "      <th id=\"T_82a17_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "      <th id=\"T_82a17_level0_col4\" class=\"col_heading level0 col4\" >Prec.</th>\n",
       "      <th id=\"T_82a17_level0_col5\" class=\"col_heading level0 col5\" >F1</th>\n",
       "      <th id=\"T_82a17_level0_col6\" class=\"col_heading level0 col6\" >Kappa</th>\n",
       "      <th id=\"T_82a17_level0_col7\" class=\"col_heading level0 col7\" >MCC</th>\n",
       "      <th id=\"T_82a17_level0_col8\" class=\"col_heading level0 col8\" >TT (Sec)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_82a17_level0_row0\" class=\"row_heading level0 row0\" >rf</th>\n",
       "      <td id=\"T_82a17_row0_col0\" class=\"data row0 col0\" >Random Forest Classifier</td>\n",
       "      <td id=\"T_82a17_row0_col1\" class=\"data row0 col1\" >0.8559</td>\n",
       "      <td id=\"T_82a17_row0_col2\" class=\"data row0 col2\" >0.8986</td>\n",
       "      <td id=\"T_82a17_row0_col3\" class=\"data row0 col3\" >0.8278</td>\n",
       "      <td id=\"T_82a17_row0_col4\" class=\"data row0 col4\" >0.8806</td>\n",
       "      <td id=\"T_82a17_row0_col5\" class=\"data row0 col5\" >0.8430</td>\n",
       "      <td id=\"T_82a17_row0_col6\" class=\"data row0 col6\" >0.7106</td>\n",
       "      <td id=\"T_82a17_row0_col7\" class=\"data row0 col7\" >0.7237</td>\n",
       "      <td id=\"T_82a17_row0_col8\" class=\"data row0 col8\" >0.0450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_82a17_level0_row1\" class=\"row_heading level0 row1\" >et</th>\n",
       "      <td id=\"T_82a17_row1_col0\" class=\"data row1 col0\" >Extra Trees Classifier</td>\n",
       "      <td id=\"T_82a17_row1_col1\" class=\"data row1 col1\" >0.8320</td>\n",
       "      <td id=\"T_82a17_row1_col2\" class=\"data row1 col2\" >0.8635</td>\n",
       "      <td id=\"T_82a17_row1_col3\" class=\"data row1 col3\" >0.7903</td>\n",
       "      <td id=\"T_82a17_row1_col4\" class=\"data row1 col4\" >0.8806</td>\n",
       "      <td id=\"T_82a17_row1_col5\" class=\"data row1 col5\" >0.8168</td>\n",
       "      <td id=\"T_82a17_row1_col6\" class=\"data row1 col6\" >0.6624</td>\n",
       "      <td id=\"T_82a17_row1_col7\" class=\"data row1 col7\" >0.6839</td>\n",
       "      <td id=\"T_82a17_row1_col8\" class=\"data row1 col8\" >0.0400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_82a17_level0_row2\" class=\"row_heading level0 row2\" >gbc</th>\n",
       "      <td id=\"T_82a17_row2_col0\" class=\"data row2 col0\" >Gradient Boosting Classifier</td>\n",
       "      <td id=\"T_82a17_row2_col1\" class=\"data row2 col1\" >0.8316</td>\n",
       "      <td id=\"T_82a17_row2_col2\" class=\"data row2 col2\" >0.8971</td>\n",
       "      <td id=\"T_82a17_row2_col3\" class=\"data row2 col3\" >0.7903</td>\n",
       "      <td id=\"T_82a17_row2_col4\" class=\"data row2 col4\" >0.8594</td>\n",
       "      <td id=\"T_82a17_row2_col5\" class=\"data row2 col5\" >0.8126</td>\n",
       "      <td id=\"T_82a17_row2_col6\" class=\"data row2 col6\" >0.6615</td>\n",
       "      <td id=\"T_82a17_row2_col7\" class=\"data row2 col7\" >0.6754</td>\n",
       "      <td id=\"T_82a17_row2_col8\" class=\"data row2 col8\" >0.0130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_82a17_level0_row3\" class=\"row_heading level0 row3\" >ada</th>\n",
       "      <td id=\"T_82a17_row3_col0\" class=\"data row3 col0\" >Ada Boost Classifier</td>\n",
       "      <td id=\"T_82a17_row3_col1\" class=\"data row3 col1\" >0.8202</td>\n",
       "      <td id=\"T_82a17_row3_col2\" class=\"data row3 col2\" >0.8924</td>\n",
       "      <td id=\"T_82a17_row3_col3\" class=\"data row3 col3\" >0.7528</td>\n",
       "      <td id=\"T_82a17_row3_col4\" class=\"data row3 col4\" >0.8649</td>\n",
       "      <td id=\"T_82a17_row3_col5\" class=\"data row3 col5\" >0.7977</td>\n",
       "      <td id=\"T_82a17_row3_col6\" class=\"data row3 col6\" >0.6385</td>\n",
       "      <td id=\"T_82a17_row3_col7\" class=\"data row3 col7\" >0.6521</td>\n",
       "      <td id=\"T_82a17_row3_col8\" class=\"data row3 col8\" >0.0170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_82a17_level0_row4\" class=\"row_heading level0 row4\" >dt</th>\n",
       "      <td id=\"T_82a17_row4_col0\" class=\"data row4 col0\" >Decision Tree Classifier</td>\n",
       "      <td id=\"T_82a17_row4_col1\" class=\"data row4 col1\" >0.8085</td>\n",
       "      <td id=\"T_82a17_row4_col2\" class=\"data row4 col2\" >0.8179</td>\n",
       "      <td id=\"T_82a17_row4_col3\" class=\"data row4 col3\" >0.8153</td>\n",
       "      <td id=\"T_82a17_row4_col4\" class=\"data row4 col4\" >0.8125</td>\n",
       "      <td id=\"T_82a17_row4_col5\" class=\"data row4 col5\" >0.8020</td>\n",
       "      <td id=\"T_82a17_row4_col6\" class=\"data row4 col6\" >0.6174</td>\n",
       "      <td id=\"T_82a17_row4_col7\" class=\"data row4 col7\" >0.6373</td>\n",
       "      <td id=\"T_82a17_row4_col8\" class=\"data row4 col8\" >0.0030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_82a17_level0_row5\" class=\"row_heading level0 row5\" >knn</th>\n",
       "      <td id=\"T_82a17_row5_col0\" class=\"data row5 col0\" >K Neighbors Classifier</td>\n",
       "      <td id=\"T_82a17_row5_col1\" class=\"data row5 col1\" >0.8018</td>\n",
       "      <td id=\"T_82a17_row5_col2\" class=\"data row5 col2\" >0.8930</td>\n",
       "      <td id=\"T_82a17_row5_col3\" class=\"data row5 col3\" >0.6903</td>\n",
       "      <td id=\"T_82a17_row5_col4\" class=\"data row5 col4\" >0.9038</td>\n",
       "      <td id=\"T_82a17_row5_col5\" class=\"data row5 col5\" >0.7550</td>\n",
       "      <td id=\"T_82a17_row5_col6\" class=\"data row5 col6\" >0.5985</td>\n",
       "      <td id=\"T_82a17_row5_col7\" class=\"data row5 col7\" >0.6303</td>\n",
       "      <td id=\"T_82a17_row5_col8\" class=\"data row5 col8\" >0.0060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_82a17_level0_row6\" class=\"row_heading level0 row6\" >lightgbm</th>\n",
       "      <td id=\"T_82a17_row6_col0\" class=\"data row6 col0\" >Light Gradient Boosting Machine</td>\n",
       "      <td id=\"T_82a17_row6_col1\" class=\"data row6 col1\" >0.7952</td>\n",
       "      <td id=\"T_82a17_row6_col2\" class=\"data row6 col2\" >0.9053</td>\n",
       "      <td id=\"T_82a17_row6_col3\" class=\"data row6 col3\" >0.7778</td>\n",
       "      <td id=\"T_82a17_row6_col4\" class=\"data row6 col4\" >0.8172</td>\n",
       "      <td id=\"T_82a17_row6_col5\" class=\"data row6 col5\" >0.7833</td>\n",
       "      <td id=\"T_82a17_row6_col6\" class=\"data row6 col6\" >0.5875</td>\n",
       "      <td id=\"T_82a17_row6_col7\" class=\"data row6 col7\" >0.6052</td>\n",
       "      <td id=\"T_82a17_row6_col8\" class=\"data row6 col8\" >0.0060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_82a17_level0_row7\" class=\"row_heading level0 row7\" >svm</th>\n",
       "      <td id=\"T_82a17_row7_col0\" class=\"data row7 col0\" >SVM - Linear Kernel</td>\n",
       "      <td id=\"T_82a17_row7_col1\" class=\"data row7 col1\" >0.7890</td>\n",
       "      <td id=\"T_82a17_row7_col2\" class=\"data row7 col2\" >0.0000</td>\n",
       "      <td id=\"T_82a17_row7_col3\" class=\"data row7 col3\" >0.7264</td>\n",
       "      <td id=\"T_82a17_row7_col4\" class=\"data row7 col4\" >0.8841</td>\n",
       "      <td id=\"T_82a17_row7_col5\" class=\"data row7 col5\" >0.7561</td>\n",
       "      <td id=\"T_82a17_row7_col6\" class=\"data row7 col6\" >0.5722</td>\n",
       "      <td id=\"T_82a17_row7_col7\" class=\"data row7 col7\" >0.6198</td>\n",
       "      <td id=\"T_82a17_row7_col8\" class=\"data row7 col8\" >0.0030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_82a17_level0_row8\" class=\"row_heading level0 row8\" >lr</th>\n",
       "      <td id=\"T_82a17_row8_col0\" class=\"data row8 col0\" >Logistic Regression</td>\n",
       "      <td id=\"T_82a17_row8_col1\" class=\"data row8 col1\" >0.7353</td>\n",
       "      <td id=\"T_82a17_row8_col2\" class=\"data row8 col2\" >0.8776</td>\n",
       "      <td id=\"T_82a17_row8_col3\" class=\"data row8 col3\" >0.7764</td>\n",
       "      <td id=\"T_82a17_row8_col4\" class=\"data row8 col4\" >0.7168</td>\n",
       "      <td id=\"T_82a17_row8_col5\" class=\"data row8 col5\" >0.7359</td>\n",
       "      <td id=\"T_82a17_row8_col6\" class=\"data row8 col6\" >0.4704</td>\n",
       "      <td id=\"T_82a17_row8_col7\" class=\"data row8 col7\" >0.4853</td>\n",
       "      <td id=\"T_82a17_row8_col8\" class=\"data row8 col8\" >0.2410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_82a17_level0_row9\" class=\"row_heading level0 row9\" >ridge</th>\n",
       "      <td id=\"T_82a17_row9_col0\" class=\"data row9 col0\" >Ridge Classifier</td>\n",
       "      <td id=\"T_82a17_row9_col1\" class=\"data row9 col1\" >0.7290</td>\n",
       "      <td id=\"T_82a17_row9_col2\" class=\"data row9 col2\" >0.0000</td>\n",
       "      <td id=\"T_82a17_row9_col3\" class=\"data row9 col3\" >0.8264</td>\n",
       "      <td id=\"T_82a17_row9_col4\" class=\"data row9 col4\" >0.6921</td>\n",
       "      <td id=\"T_82a17_row9_col5\" class=\"data row9 col5\" >0.7475</td>\n",
       "      <td id=\"T_82a17_row9_col6\" class=\"data row9 col6\" >0.4605</td>\n",
       "      <td id=\"T_82a17_row9_col7\" class=\"data row9 col7\" >0.4789</td>\n",
       "      <td id=\"T_82a17_row9_col8\" class=\"data row9 col8\" >0.0030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_82a17_level0_row10\" class=\"row_heading level0 row10\" >lda</th>\n",
       "      <td id=\"T_82a17_row10_col0\" class=\"data row10 col0\" >Linear Discriminant Analysis</td>\n",
       "      <td id=\"T_82a17_row10_col1\" class=\"data row10 col1\" >0.7169</td>\n",
       "      <td id=\"T_82a17_row10_col2\" class=\"data row10 col2\" >0.8523</td>\n",
       "      <td id=\"T_82a17_row10_col3\" class=\"data row10 col3\" >0.8389</td>\n",
       "      <td id=\"T_82a17_row10_col4\" class=\"data row10 col4\" >0.6717</td>\n",
       "      <td id=\"T_82a17_row10_col5\" class=\"data row10 col5\" >0.7428</td>\n",
       "      <td id=\"T_82a17_row10_col6\" class=\"data row10 col6\" >0.4356</td>\n",
       "      <td id=\"T_82a17_row10_col7\" class=\"data row10 col7\" >0.4556</td>\n",
       "      <td id=\"T_82a17_row10_col8\" class=\"data row10 col8\" >0.0030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_82a17_level0_row11\" class=\"row_heading level0 row11\" >nb</th>\n",
       "      <td id=\"T_82a17_row11_col0\" class=\"data row11 col0\" >Naive Bayes</td>\n",
       "      <td id=\"T_82a17_row11_col1\" class=\"data row11 col1\" >0.6871</td>\n",
       "      <td id=\"T_82a17_row11_col2\" class=\"data row11 col2\" >0.8078</td>\n",
       "      <td id=\"T_82a17_row11_col3\" class=\"data row11 col3\" >0.9000</td>\n",
       "      <td id=\"T_82a17_row11_col4\" class=\"data row11 col4\" >0.6368</td>\n",
       "      <td id=\"T_82a17_row11_col5\" class=\"data row11 col5\" >0.7404</td>\n",
       "      <td id=\"T_82a17_row11_col6\" class=\"data row11 col6\" >0.3779</td>\n",
       "      <td id=\"T_82a17_row11_col7\" class=\"data row11 col7\" >0.4260</td>\n",
       "      <td id=\"T_82a17_row11_col8\" class=\"data row11 col8\" >0.0030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_82a17_level0_row12\" class=\"row_heading level0 row12\" >qda</th>\n",
       "      <td id=\"T_82a17_row12_col0\" class=\"data row12 col0\" >Quadratic Discriminant Analysis</td>\n",
       "      <td id=\"T_82a17_row12_col1\" class=\"data row12 col1\" >0.5908</td>\n",
       "      <td id=\"T_82a17_row12_col2\" class=\"data row12 col2\" >0.7861</td>\n",
       "      <td id=\"T_82a17_row12_col3\" class=\"data row12 col3\" >0.9500</td>\n",
       "      <td id=\"T_82a17_row12_col4\" class=\"data row12 col4\" >0.5488</td>\n",
       "      <td id=\"T_82a17_row12_col5\" class=\"data row12 col5\" >0.6942</td>\n",
       "      <td id=\"T_82a17_row12_col6\" class=\"data row12 col6\" >0.1892</td>\n",
       "      <td id=\"T_82a17_row12_col7\" class=\"data row12 col7\" >0.2544</td>\n",
       "      <td id=\"T_82a17_row12_col8\" class=\"data row12 col8\" >0.0050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_82a17_level0_row13\" class=\"row_heading level0 row13\" >dummy</th>\n",
       "      <td id=\"T_82a17_row13_col0\" class=\"data row13 col0\" >Dummy Classifier</td>\n",
       "      <td id=\"T_82a17_row13_col1\" class=\"data row13 col1\" >0.5118</td>\n",
       "      <td id=\"T_82a17_row13_col2\" class=\"data row13 col2\" >0.5000</td>\n",
       "      <td id=\"T_82a17_row13_col3\" class=\"data row13 col3\" >0.0000</td>\n",
       "      <td id=\"T_82a17_row13_col4\" class=\"data row13 col4\" >0.0000</td>\n",
       "      <td id=\"T_82a17_row13_col5\" class=\"data row13 col5\" >0.0000</td>\n",
       "      <td id=\"T_82a17_row13_col6\" class=\"data row13 col6\" >0.0000</td>\n",
       "      <td id=\"T_82a17_row13_col7\" class=\"data row13 col7\" >0.0000</td>\n",
       "      <td id=\"T_82a17_row13_col8\" class=\"data row13 col8\" >0.0030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f258d6f3fa0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best = compare_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "476efe543dbe49619059d0ec6a01d912",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(ToggleButtons(description='Plot Type:', icons=('',), options=(('Hyperparameters', 'param…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluate_model(best)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('juvo_test_pycaret')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a4c1e565532e5fff16bd3446033563fd370e33105d4f015d2a3592710332b59c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
